{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 08 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. Using our own terms and diagrams, explain INCEPTIONNET ARCHITECTURE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eceabf",
   "metadata": {},
   "source": [
    "n this architecture, there is a fixed convolution size for each layer. In the Inception module 1×1, 3×3, 5×5 convolution and 3×3 max pooling performed in a parallel way at the input and the output of these are stacked together to generated final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804ecc1",
   "metadata": {},
   "source": [
    "#### 2. Describe the Inception block ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd9659",
   "metadata": {},
   "source": [
    "block that aims to approximate an optimal local sparse structure in a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### 3. What is the DIMENSIONALITY REDUCTION LAYER (1 LAYER CONVOLUTIONAL) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb2bb3",
   "metadata": {},
   "source": [
    "This effect of cross channel down-sampling is called 'Dimensionality reduction'. By adding 1X1 Conv layer before the 5X5 Conv, while keeping the height and width of the feature map, we have reduced the number of operations by a factor of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### 4. THE IMPACT OF REDUCING DIMENSIONALITY ON NETWORK PERFORMANCE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cda90d",
   "metadata": {},
   "source": [
    "f the machine learning model is trained on high-dimensional data, it becomes overfitted and results in poor performance. Hence, it is often required to reduce the number of features, which can be done with dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### 5. Mention three components. Style GoogLeNet ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283a1ba",
   "metadata": {},
   "source": [
    "This network was responsible for setting a new state-of-the-art for classification and detection in the ILSVRC. This first version of the Inception network is referred to as GoogleNet.\n",
    "\n",
    "The training used asynchronous stochastic gradient descent with a momentum of 0.9 and a fixed learning rate schedule decreasing the learning rate by 4% every 8 epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### 6. Using our own terms and diagrams, explain RESNET ARCHITECTURE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07aa22",
   "metadata": {},
   "source": [
    "ResNet, short for Residual Networks is a classic neural network used as a backbone for many computer vision tasks. This model was the winner of ImageNet challenge in 2015. The fundamental breakthrough with ResNet was it allowed us to train extremely deep neural networks with 150+layers successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### 7. What do Skip Connections entail ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e7fee",
   "metadata": {},
   "source": [
    "Skip Connections (or Shortcut Connections) as the name suggests skips some of the layers in the neural network and feeds the output of one layer as the input to the next layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### 8. What is the definition of a residual Block ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755ed18",
   "metadata": {},
   "source": [
    "A residual block is a stack of layers set in such a way that the output of a layer is taken and added to another layer deeper in the block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baff66",
   "metadata": {},
   "source": [
    "#### 9. How can transfer learning help with problems ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9664789e",
   "metadata": {},
   "source": [
    "Transfer learning models focus on storing knowledge gained while solving one problem and applying it to a different but related problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff43a28",
   "metadata": {},
   "source": [
    "#### 10. What is transfer learning, and how does it work ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bf5104",
   "metadata": {},
   "source": [
    "ransfer learning is a machine learning method where we reuse a pre-trained model as the starting point for a model on a new task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9750dd",
   "metadata": {},
   "source": [
    "#### 11.HOW DO NEURAL NETWORKS LEARN FEATURES? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6c791",
   "metadata": {},
   "source": [
    "With convolutional neural networks, the image is fed into the network in its raw form (pixels). The network transforms the image many times. First, the image goes through many convolutional layers. In those convolutional layers, the network learns new and increasingly complex features in its layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d70d79",
   "metadata": {},
   "source": [
    "#### 12. WHY IS FINE-TUNING BETTER THAN START-UP TRAINING ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307717fc",
   "metadata": {},
   "source": [
    "Fine-tuning is one approach to transfer learning where you change the model output to fit the new task and train only the output model.\n",
    "\n",
    " Assuming the original task is similar to the new task, using an artificial neural network that has already been designed and trained allows us to take advantage of what the model has already learned without having to develop it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e224c52b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
